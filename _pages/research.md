---
layout: page
title: Research
permalink: /research/
order: 5
---
I am broadly interested in Speech and Language Processing. In the modality with a speech I have a special focus on making supervised and self-supervised learning in speech and audio amenable to resource constratined scenarios (both data and compute). Currently I am also working on achieving domain invariance in supervised and self-supervised learning in speech. In the modality of text , I like working on the topics of content moderation and information extraction. I am currently focused on making deep learning models for detecting complex entities in text and help detect implicit hate speech in online conversations.

I am excited to see what multiple modalities together can offer (speech, text and graphs).

[Google Scholar profile](https://scholar.google.com/citations?user=5HKZJHAAAAAJ&hl=en)

#### **Papers (Accepted and Submitted)**

[PADA: Pruning Assisted Domain Adaptation for Self-Supervised Speech Representations](https://arxiv.org/pdf/2110.08895.pdf)   
*Lodagala V S V Durga Prasad*, Sreyan Ghosh, S. Umesh   
**Submitted to Interspeech 2022**  

[Span Classification with Structured Information for Disfluency Detection in Spoken Utterances](https://arxiv.org/pdf/2110.08895.pdf)   
*Sreyan Ghosh*, Sonal Kumar, Yaman Kumar Singla, Rajiv Ratn Shah, S. Umesh   
**Submitted to Interspeech 2022**  

[Analyzing the factors affecting usefulness of Self-Supervised Pre-trained Representations for Speech Recognition](https://arxiv.org/pdf/2110.08895.pdf)   
*Lodagala V S V Durga Prasad*, *Ashish Seth*, *Sreyan Ghosh*, S. Umesh  
**Submitted to Interspeech 2022**  

[MMER: Multimodal Multi-task learning for Emotion Recognition in Spoken Utterances](https://arxiv.org/pdf/2110.08895.pdf)   
*Sreyan Ghosh*, *Harshvardhan Srivastava*, S. Umesh   
**Submitted to Interspeech 2022**  

[A Discourse Aware Sequence Learning Approach for Emotion Recognition in Conversations](https://arxiv.org/pdf/2110.08895.pdf)   
*Sreyan Ghosh*, *Harshvardhan Srivastava*, S. Umesh   
**Submitted to Interspeech 2022**  

[DeLoRes: Decorrelating Latent Spaces for Low-Resource Audio Representation Learning](https://arxiv.org/abs/2203.13628)  
*Sreyan Ghosh*, Ashish Seth, Deepak Mittal, Maneesh Singh, S. Umesh   
**SAS Workshop @ AAAI 2022**  
**Submitted to IEEE JSTSP Special Issue on Self-Supervised Learning for Speech and Audio Processing**  

[DeToxy: A Large-Scale Multimodal Dataset for Toxicity Classification in Spoken Utterances](https://arxiv.org/pdf/2110.07592.pdf)  
*Sreyan Ghosh*, Sakshi, Samden Lepcha, Rajiv Ratn Shah, S. Umesh  
**Submitted to Interspeech 2022**

[Deep Clustering for learning general-purpose Audio Representations](https://arxiv.org/pdf/2110.08895.pdf)  
*Sreyan Ghosh*, *Ashish Seth*, *Sandesh Katta*, S. Umesh  
**Submitted to Interspeech 2022**  

[Cisco at SemEval-2021 Task 5: What's Toxic?: Leveraging Transformers for Multiple Toxic Span Extraction from Online Comments](https://aclanthology.org/2021.semeval-1.29.pdf)  
*Sreyan Ghosh*, Sonal Kumar  
**SemEval-2021 @ ACL 2021**  

[Cisco at AAAI-CAD21 shared task: Predicting Emphasis in Presentation Slides using Contextualized Embeddings](https://arxiv.org/pdf/2101.11422.pdf)  
*Sreyan Ghosh*, Sonal Kumar, Harsh Jalan, Hemant Yadav, Rajiv Ratn Shah  
**CAD-21 @ AAAI 2021**  

[End-to-end Named Entity Recognition from English Speech](https://www.isca-speech.org/archive_v0/Interspeech_2020/pdfs/2482.pdf)  
Hemant Yadav, *Sreyan Ghosh*, Yi Yu, Rajiv Ratn Shah  
**Interspeech 2020**  
