---
layout: page
title: Research
permalink: /research/
order: 5
---
I am broadly interested in Natural Language Processing (Speech and Text). In the modality of speech, I have a special focus on making supervised and self-supervised learning in speech and audio amenable to resource-constrained scenarios (both data and compute). Currently, I am also working on achieving domain invariance in supervised and self-supervised learning in speech. I also like low-resource domain adaptation as a topic of research. In the modality of text, I enjoy working on the topics of content moderation and information extraction. I am currently focused on devising better solutions for detecting complex named entities in text and detecting implicit hate speech in online conversations.

I am excited to see what multiple modalities together can offer (speech, text, audio, and graphs). I am always open to collaborations, and please feel free to drop me a mail!

<!-- #### I am always open to collaborations! Please fill out [this](https://docs.google.com/forms/d/1kQRJekonn8YglxIPH9OPcJCuI7NQK-E1wAywNAsSMoM/) form here and I would reach out if I have a project aligned with your interests. Thank You! -->

<!-- P.S. : Though I acknowledge that achieving state-of-the-art (SOTA) results is not and should not be the final goal of research, I am proud that some of my works achieve SOTA on some well known Speech and Language Processing task (until November 2022). Here are the links for [ASR (Librispeech 360hr train split)](http://arxiv.org/abs/2211.01246), [Keyword Spotting (Speech Commands 1)](http://arxiv.org/abs/2211.01515), [Speech Emotion Recognition (IEMOCAP)](http://arxiv.org/abs/2203.16794), [Disfleuncy Detection (SwitchBoard)](http://arxiv.org/abs/2203.16028) and [Low-resource General Purpose Audio Representation Learning](http://arxiv.org/abs/2211.01515). -->

[Google Scholar](https://scholar.google.com/citations?user=5HKZJHAAAAAJ&hl=en) [Semantic Scholar](https://www.semanticscholar.org/author/Sreyan-Ghosh/3488077)  


### Under Review

* [CoSyn: Detecting Implicit Hate Speech in Online Conversations Using a Context Synergized Hyperbolic Network](http://arxiv.org/abs/2303.03387)   
*Sreyan Ghosh*\*, Manan Suri\*, Purva Chiniya\*, Utkarsh Tyagi\*, Sonal Kumar\*, Dinesh Manocha  
[Code](https://github.com/Sreyan88/CoSyn)  
**Under review at EMNLP 2023**  


### Pre-print

* [Deep Clustering for learning general-purpose Audio Representations](https://arxiv.org/pdf/2110.08895.pdf)  
*Sreyan Ghosh*\*, Ashish Seth\*, Sandesh Katta\*, S. Umesh  
[Code](https://github.com/Sreyan88/LAPE)  
**Pre-print**  

* [Analyzing the factors affecting usefulness of Self-Supervised Pre-trained Representations for Speech Recognition](http://arxiv.org/abs/2203.16973)  
Lodagala V S V Durga Prasad\*, Ashish Seth\*, *Sreyan Ghosh*\*, S. Umesh  
**Pre-print**  

### Journal

* [Decorrelating Feature Spaces for Learning General Purpose Audio Representations](https://ieeexplore.ieee.org/document/9868132)    
*Sreyan Ghosh*\*, Ashish Seth\*, S. Umesh    
[Code](https://github.com/Sreyan88/LAPE) [Poster](../assets/delores_poster_final.pdf)  
**IEEE JSTSP Special Issue on Self-Supervised Learning for Speech and Audio Processing**  
**ICASSP 2023 (Poster)**  

### Conference

* [MMER: Multimodal Multi-task Learning for Speech Emotion Recognition](http://arxiv.org/abs/2203.16794)  
*Sreyan Ghosh*, Utkarsh Tyagi, S Ramaneswaran, Harshvardhan Srivastava, Dinesh Manocha  
[Code](https://github.com/Sreyan88/MMER)  
**Interspeech 2023**  

* [ACLM: A Selective-Denoising based Generative Data Augmentation Approach for Low-Resource Complex NER](https://arxiv.org/abs/2306.00928v1)  
*Sreyan Ghosh*\*, Utkarsh Tyagi\*, Manan Suri, Sonal Kumar, S Ramaneswaran, Dinesh Manocha  
[Code](https://github.com/Sreyan88/ACLM) [Poster](../assets/acl_final_poster.pdf)  
**ACL 2023 (Poster)**  

* [BioAug: Conditional Generation based Data Augmentation for Low-Resource Biomedical NER](https://arxiv.org/abs/2305.10647)  
*Sreyan Ghosh*\*, Utkarsh Tyagi\*, Sonal Kumar\*, Dinesh Manocha  
[Code](https://github.com/Sreyan88/BioAug)  
**SIGIR 2023 (Poster)**  

* [data2vec-aqc: Search for the right Teaching Assistant in the Teacher-Student training setup](https://arxiv.org/abs/2211.01246)  
Lodagala V S V Durga Prasad\*, *Sreyan Ghosh*\*, S. Umesh  
[Code](https://github.com/Speech-Lab-IITM/data2vec-aqc) [Leaderboard](https://superbbenchmark.org/leaderboard?subset=Public+Set)  
**ICASSP 2023 (Oral)**  

* [MAST: Multiscale Audio Spectrogram Transformers](http://arxiv.org/abs/2211.01515)  
*Sreyan Ghosh*\*, Ashish Seth\*, S. Umesh, Dinesh Manocha  
[Code](https://github.com/Sreyan88/LAPE) [Poster](../assets/mast_poster_final.pdf)  
**ICASSP 2023 (Poster)**  

* [SLICER: Learning universal audio representations using low-resource self-supervised pre-training](http://arxiv.org/abs/2211.01519)  
Ashish Seth\*, *Sreyan Ghosh*\*, S. Umesh, Dinesh Manocha  
[Code](https://github.com/Sreyan88/LAPE) [Poster](../assets/slicer_poster_final.pdf)  
**ICASSP 2023 (Poster)**  

* [PADA: Pruning Assisted Domain Adaptation for Self-Supervised Speech Representations](http://arxiv.org/abs/2203.16965)   
Lodagala V S V Durga Prasad, *Sreyan Ghosh*, S. Umesh  
[Code](https://github.com/Speech-Lab-IITM/PADA)  
**IEEE SLT 2022**  

* [CCC-WAV2VEC 2.0: Clustering aided cross contrastive self-supervised learning of speech representations](http://arxiv.org/abs/2210.02592)   
Lodagala V S V Durga Prasad, *Sreyan Ghosh*, S. Umesh  
[Code](https://github.com/Speech-Lab-IITM/CCC-wav2vec-2.0)  [Leaderboard](https://superbbenchmark.org/leaderboard?subset=Public+Set)  
**IEEE SLT 2022**  

* [Span Classification with Structured Information for Disfluency Detection in Spoken Utterances](http://arxiv.org/abs/2203.16028)  
*Sreyan Ghosh*, Sonal Kumar, Yaman Kumar Singla, Rajiv Ratn Shah, S. Umesh  
[Code](https://github.com/Sreyan88/Disfluency-Detection-with-Span-Classification)  
**Interspeech 2022 (Oral)**  

* [DeToxy: A Large-Scale Multimodal Dataset for Toxicity Classification in Spoken Utterances](https://arxiv.org/pdf/2110.07592.pdf)  
*Sreyan Ghosh*, Samden Lepcha, Sakshi, Rajiv Ratn Shah, S. Umesh  
[Code](https://github.com/Sreyan88/Toxicity-Detection-in-Spoken-Utterances) [Data](https://github.com/Sreyan88/Toxicity-Detection-in-Spoken-Utterances/tree/main/data)  
**Interspeech 2022 (Poster)**  

* [End-to-end Named Entity Recognition from English Speech](https://www.isca-speech.org/archive_v0/Interspeech_2020/pdfs/2482.pdf)  
Hemant Yadav, *Sreyan Ghosh*, Yi Yu, Rajiv Ratn Shah  
[Code](https://github.com/raotnameh/End-to-end-E2E-Named-Entity-Recognition-from-English-Speech) [Data](https://zenodo.org/record/3893954)  
**Interspeech 2020 (Poster)**  

### Workshop

* [UNFUSED: UNsupervised Finetuning Using SElf supervised Distillation](https://arxiv.org/abs/2303.05668)  
Ashish Seth\*, Sreyan Ghosh\*, S. Umesh, Dinesh Manocha  
[Code](https://github.com/Sreyan88/LAPE) [Poster](../assets/unfused_final.pdf)  
**ICASSP 2023 SASB Workshop**  

* [DeLoRes: Decorrelating Latent Spaces for Low-Resource Audio Representation Learning](https://arxiv.org/abs/2203.13628)   
*Sreyan Ghosh*, Ashish Seth, Deepak Mittal, Maneesh Singh, S. Umesh   
[Code](https://github.com/Speech-Lab-IITM/DeLoRes)  
**SAS Workshop @ AAAI 2022**    

* [Leveraging Transformers for Hate Speech Detection in Conversational Code-Mixed Tweets](https://arxiv.org/pdf/2112.09986.pdf)    
Zaki Mustafa Farooqi, *Sreyan Ghosh*, Rajiv Ratn Shah  
[Leader Board (Team Name: MIDAS@IIIT-D)](https://hasocfire.github.io/hasoc/2021/results.html#)  
**FIRE 2021**  

* [Cisco at SemEval-2021 Task 5: What's Toxic?: Leveraging Transformers for Multiple Toxic Span Extraction from Online Comments](https://aclanthology.org/2021.semeval-1.29.pdf)  
*Sreyan Ghosh*, Sonal Kumar  
[Code](https://github.com/Sreyan88/SemEval-2021-Toxic-Spans-Detection)  
**SemEval-2021 @ ACL 2021**  

* [Cisco at AAAI-CAD21 shared task: Predicting Emphasis in Presentation Slides using Contextualized Embeddings](https://arxiv.org/pdf/2101.11422.pdf)   
*Sreyan Ghosh*, Sonal Kumar, Harsh Jalan, Hemant Yadav, Rajiv Ratn Shah  
[Code](https://github.com/Sreyan88/CAD21-AAAI21)  
**CAD-21 @ AAAI 2021**  


