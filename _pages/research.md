---
layout: page
title: Research
permalink: /research/
order: 5
---
My research focuses on deep learning for audio processing, with a focus on building efficient models and the integration of language as a tool to improve the performance of audio processing tasks.

I am always open to collaborations, and please feel free to drop me a mail!  

<!-- #### I am always open to collaborations! Please fill out [this](https://docs.google.com/forms/d/1kQRJekonn8YglxIPH9OPcJCuI7NQK-E1wAywNAsSMoM/) form here and I would reach out if I have a project aligned with your interests. Thank You! -->

<!-- P.S. : Though I acknowledge that achieving state-of-the-art (SOTA) results is not and should not be the final goal of research, I am proud that some of my works achieve SOTA on some well known Speech and Language Processing task (until November 2022). Here are the links for [ASR (Librispeech 360hr train split)](http://arxiv.org/abs/2211.01246), [Keyword Spotting (Speech Commands 1)](http://arxiv.org/abs/2211.01515), [Speech Emotion Recognition (IEMOCAP)](http://arxiv.org/abs/2203.16794), [Disfleuncy Detection (SwitchBoard)](http://arxiv.org/abs/2203.16028) and [Low-resource General Purpose Audio Representation Learning](http://arxiv.org/abs/2211.01515). -->

[Google Scholar](https://scholar.google.com/citations?hl=en&user=F_-YNVAAAAAJ) 


<!-- ### Pre-prints  

* [GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities](https://arxiv.org/abs/2406.11768)    
Sreyan Ghosh\*, Sonal Kumar\*, Ashish Seth, Chandra Kiran Reddy Evuru, Utkarsh Tyagi, *S Sakshi*, Oriol Nieto, Ramani Duraiswami, Dinesh Manocha  
[Project Website](https://sreyan88.github.io/gamaaudio/)  / [Summary Tweet](https://x.com/SreyanG/status/1803075223992115276) / [Coverage 1](https://www.cs.umd.edu/article/2024/07/umd-researchers-release-gama-llm-advanced-audio-understanding) / [Coverage 2](https://the-vision-debugged.beehiiv.com/p/ep-23-shhh-can-you-hear-that-gama-can)    
**Pre-print**  

* [EH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning](https://drive.google.com/file/d/1ISRRZrUdHF7h1QreBiJzxBlcEA6Otr3n/view)    
Ashish Seth\*, Ramaneswaran S\*, *S Sakshi*\*, Sonal Kumar, Dinesh Manocha  
**Pre-print**   -->


### Accepted Papers

* [EH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning](https://openreview.net/pdf?id=N06hbHULIP)    
Ashish Seth\*, Ramaneswaran S\*, *S Sakshi*, Sonal Kumar, Dinesh Manocha  
**EMNLP 2024** 

* [GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities](https://arxiv.org/abs/2406.11768)    
Sreyan Ghosh\*, Sonal Kumar\*, Ashish Seth, Chandra Kiran Reddy Evuru, Utkarsh Tyagi, *S Sakshi*, Oriol Nieto, Ramani Duraiswami, Dinesh Manocha  
[Project Website](https://sreyan88.github.io/gamaaudio/)  / [Summary Tweet](https://x.com/SreyanG/status/1803075223992115276) / [Coverage 1](https://www.cs.umd.edu/article/2024/07/umd-researchers-release-gama-llm-advanced-audio-understanding) / [Coverage 2](https://the-vision-debugged.beehiiv.com/p/ep-23-shhh-can-you-hear-that-gama-can)    
**EMNLP 2024**

* [ASPIRE: Language-Guided Augmentation for Robust Image Classification](https://arxiv.org/abs/2308.10103)  
*Sreyan Ghosh*\*, Chandra Kiran Reddy Evuru\*, Sonal Kumar\*, *S Sakshi*, Utkarsh Tyagi, Dinesh Manocha  
[Code](https://github.com/Sreyan88/ASPIRE)  / [Poster](../assets/ACL-ASPIRE.pdf)  
**ACL 2024 Findings**  

* [Do Vision-Language Models Understand Compound Nouns?](https://arxiv.org/abs/2404.00419)  
Sonal Kumar\*, *Sreyan Ghosh*\*, *S Sakshi*, Utkarsh Tyagi, Dinesh Manocha    
[Code](https://github.com/sonalkum/Compun) / [Poster](../assets/compun_naacl_poster.pdf)    
**NAACL 2024**  

* [DALE: Generative Data Augmentation for Low-Resource Legal NLP](https://arxiv.org/abs/2310.15799)    
*Sreyan Ghosh*\*, Chandra Kiran Reddy Evuru\*, Sonal Kumar, Ramaneswaran S, *S Sakshi*, Utkarsh Tyagi, Dinesh Manocha  
[Code](https://github.com/Sreyan88/DALE) / [Poster](../assets/DALE_poster_EMNLP.pdf)  
**EMNLP 2023**    

* [CompA: Addressing the Gap in Compositional Reasoning in Audio-Language Models](https://arxiv.org/abs/2310.08753)  
*Sreyan Ghosh*\*, Ashish Seth\*, Sonal Kumar\*, Utkarsh Tyagi\*, Chandra Kiran Reddy Evuru\*, Ramaneswaran S, *S Sakshi*, Oriol Nieto, Ramani Duraiswami, Dinesh Manocha  
[Project Webiste](https://sreyan88.github.io/compa_iclr/) / [Slides](../assets/ICLR_Presentation.pdf) / [Poster](../assets/iclr_poster.pdf)      
**ICLR 2024**  

* [DeToxy: A Large-Scale Multimodal Dataset for Toxicity Classification in Spoken Utterances](https://arxiv.org/pdf/2110.07592.pdf)  
*Sreyan Ghosh*, Samden Lepcha, *Sakshi*, Rajiv Ratn Shah, S. Umesh  
[Code](https://github.com/Sreyan88/Toxicity-Detection-in-Spoken-Utterances) / [Data](https://github.com/Sreyan88/Toxicity-Detection-in-Spoken-Utterances/tree/main/data)  
**Interspeech 2022**  