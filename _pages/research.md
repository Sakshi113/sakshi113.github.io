---
layout: page
title: Research
permalink: /research/
order: 5
---
I am broadly interested in Natural Language Processing (Speech and Text). In the modality of speech, I have a special focus on making supervised and self-supervised learning in speech and audio amenable to resource constratined scenarios (both data and compute). Currently I am also working on achieving domain invariance in supervised and self-supervised learning in speech. I also like low-resource domain adaptation as a topic of research. In the modality of text, I like working on the topics of content moderation and information extraction. I am currently focused on making deep learning models for detecting complex entities in text and help detect implicit hate speech in online conversations.

I am excited to see what multiple modalities together can offer (speech, text and graphs).

<!-- P.S. : Though I acknowledge that achieving state-of-the-art (SOTA) results is not and should not be the final goal of research, I am proud that some of my works achieve SOTA on some well known Speech and Language Processing task (until November 2022). Here are the links for [ASR (Librispeech 360hr train split)](http://arxiv.org/abs/2211.01246), [Keyword Spotting (Speech Commands 1)](http://arxiv.org/abs/2211.01515), [Speech Emotion Recognition (IEMOCAP)](http://arxiv.org/abs/2203.16794), [Disfleuncy Detection (SwitchBoard)](http://arxiv.org/abs/2203.16028) and [Low-resource General Purpose Audio Representation Learning](http://arxiv.org/abs/2211.01515). -->

[Google Scholar](https://scholar.google.com/citations?user=5HKZJHAAAAAJ&hl=en)

### **Papers**
##### **(names in italics indicate main contributor or equal contribution)**

#### **Under Review**

M-MELD: A Multilingual Multi-Party Dataset for Emotion Recognition in Conversations  
*Sreyan Ghosh*, *S Ramaneswaran*, *Utkarsh Tyagi*, Harshvardhan Srivastava, Samden Lepcha, S Sakshi, Dinesh Manocha  
[arXiv](http://arxiv.org/abs/2203.16799) [Code](https://github.com/Sreyan88/M-MELD)  
**Under review at Interspeech 2023**  

#### **Pre-print**

Deep Clustering for learning general-purpose Audio Representations  
*Sreyan Ghosh*, *Ashish Seth*, *Sandesh Katta*, S. Umesh  
[arXiv](https://arxiv.org/pdf/2110.08895.pdf) [Code](https://github.com/Speech-Lab-IITM/DECAR) 
**Pre-print**   

Speech Emotion Recognition using Multi-task learning and a multimodal dynamic fusion network  
*Sreyan Ghosh*, Harshvardhan Srivastava, S. Umesh   
[arXiv](http://arxiv.org/abs/2203.16794) [Code](https://github.com/Sreyan88/MMER)  
**Pre-print**  

Analyzing the factors affecting usefulness of Self-Supervised Pre-trained Representations for Speech Recognition  
*Lodagala V S V Durga Prasad*, *Ashish Seth*, *Sreyan Ghosh*, S. Umesh  
[arXiv](http://arxiv.org/abs/2203.16973) [Checkpoints](https://github.com/Sreyan88/Disfluency-Detection-with-Span-Classification) [Leader Board](https://sites.google.com/view/gramvaaniasrchallenge/leaderboard?authuser=0)  
**Pre-print**  

#### **Journal**

Decorrelating Feature Spaces for Learning General Purpose Audio Representations   
*Sreyan Ghosh*, Ashish Seth, S. Umesh    
[Paper](https://ieeexplore.ieee.org/document/9868132) [Code](https://github.com/Speech-Lab-IITM/Decorrelating-Feature-Spaces-for-Learning-General-Purpose-Audio-Representations)  
**IEEE JSTSP Special Issue on Self-Supervised Learning for Speech and Audio Processing**  

#### **Conference**

data2vec-aqc: Search for the right Teaching Assistant in the Teacher-Student training setup  
*Lodagala V S V Durga Prasad*, *Sreyan Ghosh*, S. Umesh  
[arXiv](https://arxiv.org/abs/2211.01246)  
**ICASSP 2023**  

MAST: Multiscale Audio Spectrogram Transformers  
*Sreyan Ghosh*, *Ashish Seth*, S. Umesh, Dinesh Manocha  
[arXiv](http://arxiv.org/abs/2211.01515)  
**ICASSP 2023**  

SLICER: Learning universal audio representations using low-resource self-supervised pre-training  
*Ashish Seth*, *Sreyan Ghosh*, S. Umesh, Dinesh Manocha  
[arXiv](http://arxiv.org/abs/2211.01519)  
**ICASSP 2023**  

PADA: Pruning Assisted Domain Adaptation for Self-Supervised Speech Representations   
*Lodagala V S V Durga Prasad*, Sreyan Ghosh, S. Umesh  
[arXiv](http://arxiv.org/abs/2203.16965) [Code](https://github.com/Speech-Lab-IITM/PADA)  
**IEEE SLT 2022**  

CCC-WAV2VEC 2.0: Clustering aided cross contrastive self-supervised learning of speech representations   
*Lodagala V S V Durga Prasad*, Sreyan Ghosh, S. Umesh  
[arXiv](http://arxiv.org/abs/2210.02592)  [Code](https://github.com/Speech-Lab-IITM/CCC-wav2vec-2.0)  
**IEEE SLT 2022**  

Span Classification with Structured Information for Disfluency Detection in Spoken Utterances  
*Sreyan Ghosh*, Sonal Kumar, Yaman Kumar Singla, Rajiv Ratn Shah, S. Umesh  
[arXiv](http://arxiv.org/abs/2203.16028) [Code](https://github.com/Sreyan88/Disfluency-Detection-with-Span-Classification)  
**Interspeech 2022 (Oral)**  

DeToxy: A Large-Scale Multimodal Dataset for Toxicity Classification in Spoken Utterances  
*Sreyan Ghosh*, Sakshi, Samden Lepcha, Rajiv Ratn Shah, S. Umesh  
[arXiv](https://arxiv.org/pdf/2110.07592.pdf) [Code](https://github.com/Sreyan88/Toxicity-Detection-in-Spoken-Utterances) [Data](https://github.com/Sreyan88/Toxicity-Detection-in-Spoken-Utterances/tree/main/data)  
**Interspeech 2022 (Poster)**  

End-to-end Named Entity Recognition from English Speech  
*Hemant Yadav*, Sreyan Ghosh, Yi Yu, Rajiv Ratn Shah  
[arXiv](https://www.isca-speech.org/archive_v0/Interspeech_2020/pdfs/2482.pdf) [Code](https://github.com/raotnameh/End-to-end-E2E-Named-Entity-Recognition-from-English-Speech) [Data](https://zenodo.org/record/3893954)  
**Interspeech 2020 (Poster)**  

#### **Workshop**

DeLoRes: Decorrelating Latent Spaces for Low-Resource Audio Representation Learning  
*Sreyan Ghosh*, Ashish Seth, Deepak Mittal, Maneesh Singh, S. Umesh   
[arXiv](https://arxiv.org/abs/2203.13628) [Code](https://github.com/Speech-Lab-IITM/DeLoRes)  
**SAS Workshop @ AAAI 2022**    

Leveraging Transformers for Hate Speech Detection in Conversational Code-Mixed Tweets  
*Zaki Mustafa Farooqi*, Sreyan Ghosh, Rajiv Ratn Shah  
[arXiv](https://arxiv.org/pdf/2112.09986.pdf) [Leader Board (Team Name: MIDAS@IIIT-D)](https://hasocfire.github.io/hasoc/2021/results.html#)  
**FIRE 2021**  

Cisco at SemEval-2021 Task 5: What's Toxic?: Leveraging Transformers for Multiple Toxic Span Extraction from Online Comments  
*Sreyan Ghosh*, Sonal Kumar  
[arXiv](https://aclanthology.org/2021.semeval-1.29.pdf) [Code](https://github.com/Sreyan88/SemEval-2021-Toxic-Spans-Detection)  
**SemEval-2021 @ ACL 2021**  

Cisco at AAAI-CAD21 shared task: Predicting Emphasis in Presentation Slides using Contextualized Embeddings  
*Sreyan Ghosh*, Sonal Kumar, Harsh Jalan, Hemant Yadav, Rajiv Ratn Shah  
[arXiv](https://arxiv.org/pdf/2101.11422.pdf) [Code](https://github.com/Sreyan88/CAD21-AAAI21)  
**CAD-21 @ AAAI 2021**  


